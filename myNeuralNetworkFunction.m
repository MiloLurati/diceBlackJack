function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Auto-generated by MATLAB, 09-Dec-2020 11:30:05.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = Qx12 matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = Qx3 matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [-5.10614907663519;-0.161431244444348;-0.700250845280922;-0.326172054713904;-0.374397195003094;-0.499962737492005;-0.362747849037614;-0.280695108900057;-0.284387834497779;-0.166690425500918;-0.186107145344891;-0.0915742980451523];
x1_step1.gain = [0.273520899802735;2.04663821272087;1.75622372824834;2.95843297100745;2.8792426145886;2.75226041759576;4.32446972861774;4.49457796139732;4.99221648905578;6.49356275033899;8.91045974315863;8.74430517749176];
x1_step1.ymin = -1;

% Layer 1
b1 = [1.6383240415376476573;0.099313043755741126084;0.096724201436067691606;0.77655387980792978109;0.47979921375673978412;-0.60407722655879259044;0.040105213491506003232;-1.0307753700741175695;1.3191414709863511501;1.5289125424811604859];
IW1_1 = [-0.086555668347400582796 0.8510518096347576833 -0.44624575052769538397 -0.95943077261711817716 0.29923987956371822516 0.41074648557619053424 0.33260983624553147608 0.31867667678550398724 0.054301239481962186584 0.22718131729682608522 -0.11357985943256551642 -0.72187630673416736116;-0.69369311925752086267 0.16751319310603043911 1.2739917646681129249 0.079484402736302001147 -1.2490361098130609019 -1.4207474209784280994 0.24042931226141661671 1.6176172415337366495 1.0388121179333302813 -0.40537164355434296414 -0.19783733740100775678 0.51707732944301765254;-0.66638127551070436283 0.81752546715288720858 0.9833016559069676088 -0.22419661405505716956 -1.0191518616945751674 -1.198914881174565128 0.21621003720342191201 0.1333899022766065201 -0.46242251440467291301 0.16946963947496840319 0.32632949097938251937 0.17734064396202489644;-0.75048910596818607655 -0.86051902796860391121 -0.93062135090718600683 0.23717220088355586705 0.38497453017969757161 0.3828767854557945105 -0.19741893107343530533 0.026082280958888273692 -0.46315667723577896853 0.22982839770582558225 0.60597178396409201451 0.75050379807168976498;-0.45609779359938118493 0.025123978328853706354 -0.17916716340375329897 0.67738354586914251154 0.96094963147302325801 0.80147960757771197216 0.064713076139741518289 -0.74285768032709653674 -0.89039976279803234593 1.0345677160254407312 0.39228470661003178588 -0.20595153661643789134;-0.19068729390536415247 -0.15342883397383094701 0.71943674402487778341 -0.39465412239783692616 -1.3621925500094500538 0.39521262176895211038 0.21532548969701023611 1.5186993388784251202 0.95295105525466228258 -0.91599611166476457846 0.2928046243716012631 -0.13298503160206037732;-0.16603916672369817276 0.50247451574651014194 -0.59201693601248317478 0.28288077228068880808 -0.38983634441932651926 0.25743359319967701326 0.17633812410494520417 1.2963115131305995575 0.4842662460744648345 -1.1430079800217760599 0.56846405278461464849 0.34012581742076752889;-0.084783482533029530526 0.39804468608244969463 0.18447614762324412996 0.033729976367986615193 -0.54493444225808318482 -0.15401846618337813877 0.14372264736247328254 -0.69864952866412977084 -0.015642229413992785048 -0.86795299287135851962 -0.68092200951921832974 0.6610323470101765464;0.62680617878253930275 -0.48785303645843286491 0.10703475360010505923 -1.1928441237806677311 0.35875789601107144211 -1.0171057404328913698 -0.87841855477356134418 0.231938567621146563 0.22564697440554948304 -0.55192227009172745156 -0.34828571088120408028 -0.3103062549545137494;-0.10000505566504440391 -0.53400474815680121221 1.0832980397326334998 -0.76053348894799399638 -0.62829263309277827432 0.47639467521840783704 0.11965312257958586606 0.29041040657265415614 0.17337711149483034379 -0.25560151775716677403 0.57822343036863665944 -0.34540398396981591977];

% Layer 2
b2 = [0.98510330003145474276;-0.36248244340324253798;0.27364657612527126807];
LW2_1 = [-0.70562627847040360063 -2.436360175349513213 -1.028682546611638049 0.49620871190064130829 0.77874558702475604743 -2.4855170094616365617 -1.2107779173131549832 0.61299430779708297123 0.78552851065057527347 -0.4705354968950459793;0.16411537787751051543 2.3188556592581122118 1.5646336313176927302 -0.53522702461192372958 -1.5664338518789386878 0.67154062973432337991 0.12444492949744064003 0.4306382344793128758 1.221450794809579854 -0.45556254334295753772;-0.46201982182520290321 -0.79815004924784016538 -0.55709786765823332555 0.66794514580716912722 0.11954919939609406909 0.86485198068586088826 0.98372577269577810011 0.052504131935229667039 -1.0862138816440647382 0.69374139776482435238];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},1); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    X{1,ts} = X{1,ts}';
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
    Y{1,ts} = Y{1,ts}';
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
